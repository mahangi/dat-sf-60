{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Experiments and Hypothesis Testing\n",
    "\n",
    "_Authors: Alexander Egorenkov (DC), etc._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "### Learning Objectives\n",
    "- Explain the difference between causation and correlation\n",
    "- Understand and calculate basic descriptive statistics - mean, median, mode, range, variance, standard deviation\n",
    "- Know when to use a box plot and how to draw it using Pandas\n",
    "- Understand what a normal distribution is\n",
    "- Identify what missing data is and how to handle it\n",
    "- Test a hypothesis using a sample case study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Lesson Guide\n",
    "- [Data source](#data)\n",
    "\t- [Exploring the advertising data](#exploring)\n",
    "- [Descriptive statistics fundamentals](#descriptive)\n",
    "    - [Math review](#math)\n",
    "        - [Independent exercise 1](#ie1)\n",
    "        - [Measures of central tendency](#measures)\n",
    "        - [Independent exercise 2](#ie2)\n",
    "        - [Anscombe's quartet](#anscombe)\n",
    "        - [Box plots: Show quartiles (and outliers) for one or more numerical variables](#box)\n",
    "    - [Measuring distance](#distance)\n",
    "    - [Measures of dispersion: Standard deviation and variance](#dispersion)\n",
    "        - [Independent exercise 3](#ie3)\n",
    "    - [Understanding distributions](#distributions)\n",
    "        - [What is the normal distribution?](#what)\n",
    "        - [Sampling bias](#sampling)\n",
    "    - [Measuring relationships](#relationships)\n",
    "        - [Covariance](#covariance)\n",
    "        - [Correlation](#correlation)\n",
    "        - [The variance-covariance matrix](#matrix)\n",
    "        - [Independent exercise 4](#ie4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [Optional](#optional):\n",
    "- [Missing data](#missing)\n",
    "\t- [Types of missing data](#types)\n",
    "\t- [Class imbalance](#class)\n",
    "  \t- [Error types](#error)\n",
    "- [Introduction to hypothesis testing](#hypothesis)\n",
    "\t- [Validate your findings](#validate)\n",
    "\t- [Confidence intervals](#confidence)\n",
    "- [Relation to machine learning](#relation)\n",
    "- [Additional practice materials](#practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"data\"></a>\n",
    "## Data source\n",
    "\n",
    "---\n",
    "\n",
    "Today, we’ll use advertising data from an example in the book [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/).\n",
    "- This is a well-known, standard introduction to machine learning.\n",
    "- The book has a more advanced version — [Elements of Statistical Learning](http://web.stanford.edu/~hastie/ElemStatLearn/) — if you are comfortable with linear algebra and statistics at the graduate level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Code-Along: Importing Today's Data\\*\n",
    "> **\\***You may need to install `seaborn` before you can use it. To do so, just run:  \n",
    "> `$ conda install seaborn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# this selects the 'style' that matplotlib will use to generate plots\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# read data into a DataFrame\n",
    "\n",
    "# we use index_col to tell Pandas that the first column in the data has row labels\n",
    "data = pd.read_csv('http://faculty.marshall.usc.edu/gareth-james/ISL/Advertising.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## examine the data\n",
    "# print the shape\n",
    "print(f'date shape: {data.shape}')\n",
    "\n",
    "# print the first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"exploring\"></a>\n",
    "### Exploring the advertising data\n",
    "\n",
    "Let's pretend you work for the company that manufactures and markets this new device.\n",
    "\n",
    "The company might ask you the following: \n",
    "> _\"On the basis of this data, how should we spend our advertising money in the future?\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### What are the 'features', 'independent variables', or 'predictors'?\n",
    "> **i.e. $X$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### What is the 'outcome', 'dependent variable', or 'response'?\n",
    "> **i.e. $y$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### What do you think each *row* in the data set represents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"descriptive\"></a>\n",
    "## Descriptive statistics fundamentals\n",
    "---\n",
    "\n",
    "- **Objective:** Code summary statistics using NumPy and Pandas: mean, median, mode, max, min, quartile, inter-quartile range, variance, standard deviation, and correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"math\"></a>\n",
    "### Math review\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Sigma Notation: A Quick Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The sum of a constant, $k$, $n$ times:\n",
    "$$\\sum_{i=1}^nk$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# k + k + k + k + ... + k\n",
    "# -or-\n",
    "# total = sum(k for i in range(1, n+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The sum of all numbers from 1 up to and including $n$:\n",
    "$$\\sum_{i=1}^ni$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 1 + 2 + 3 + ... + n\n",
    "# -or-\n",
    "# total = sum(range(1, n+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The sum of all $x$ from the first $x$ entry to the $n$th $x$ entry:\n",
    "$$\\sum_{i=1}^nx_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# x_1 + x_2 + x_3 + ... + x_n\n",
    "# -or-\n",
    "# total = sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"ie1\"></a>\n",
    "\n",
    "#### Independent exercise 1 (~5 minutes)\n",
    "\n",
    "(_Optional: Try writing down the mathematical notation for the following questions, as well._)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# compute the sum of seven 4s using base Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the sum of seven 4s using NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the sum of 1 through 10 using base Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the data.TV column, compute the total spent on TV advertising budgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"measures\"></a>\n",
    "### Measures of central tendency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Mean\n",
    "- Median\n",
    "- Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Mean\n",
    "The mean — also known as the average or expected value — is defined as:\n",
    "$$E[X] = \\bar{X} =\\frac 1n\\sum_{i=1}^nx_i$$\n",
    "\n",
    "It is determined by summing all data points in a population and then dividing the total by the number of points. The resulting number is known as the mean or the average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> *Be careful* — **the mean can be highly affected by outliers**. \n",
    "> - For example, the mean of a very large number and some small numbers will be much larger than the \"typical\" small numbers. \n",
    "> - Earlier, we saw that the mean squared error (MSE) was used to optimize linear regression. \n",
    "> - Because this mean is highly affected by outliers, the resulting linear regression model is, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Median\n",
    "The median refers to the midpoint in a series of numbers. To find the median:\n",
    "\n",
    "- Arrange the numbers in order from smallest to largest.\n",
    "    - If there is an odd number of values, the middle value is the median.\n",
    "    - If there is an even number of values, the average of the middle two values is the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that the median is not as affected by outliers. So, when extreme outliers are present, it does a better job of representing the \"typical\" value in a set.\n",
    "\n",
    "$$ 0,1,2,[3],5,5,1004 $$\n",
    "\n",
    "$$ 1,3,4,[4,5],5,5,7 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Although the median has many useful properties, the mean is easier to use in optimization algorithms.\n",
    "- Consequently, median is more often used in analysis than in machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Mode\n",
    "The mode of a set of values is the value that occurs most often.\n",
    "A set of values may have more than one mode, or no mode at all.\n",
    "\n",
    "$$1,0,1,5,7,8,9,3,4,1$$ \n",
    "\n",
    "$1$ is the mode, as it occurs the most often (three times)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"ie2\"></a>\n",
    "#### Independent exercise 2 (~10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean of the data.radio series using base Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean of the data.radio series using NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean of the data.radio series using Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what was the median advertising budget for radio (using Pandas)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Pandas to find the most common budget amount among all 200 markets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id='anscombe'></a>\n",
    "\n",
    "### Anscombe's quartet\n",
    "\n",
    "---\n",
    "\n",
    "These descriptive statistics come from a data set constructed in 1973 by the statistician Francis Anscombe. \n",
    "- It's a classic demonstration of the importance of *data visualization*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Below are the summary statistics for four plots. \n",
    "- **What do you think the visualization for each plot would look like?**\n",
    "\n",
    "<img src=\"./assets/quartet.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can probably already guess what the answer is: Although the four plots have the same summary statistics, \n",
    "they are actually completely different. \n",
    "- **Look what happens when we visualize them together.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./assets/quartet_viz.png\" style=\"margin: auto; width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"box\"></a>\n",
    "### Box plots: Show quartiles (and outliers) for one or more numerical variables\n",
    "---\n",
    "\n",
    "We can use boxplots to ***quickly summarize distributions***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Box plots are *packed* with good info!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Five-number summary:**\n",
    "- min = minimum value\n",
    "- 25% = first quartile (Q1) = median of the lower half of the data\n",
    "- 50% = second quartile (Q2) = median of the data\n",
    "- 75% = third quartile (Q3) = median of the upper half of the data\n",
    "- max = maximum value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(It's more useful than mean and standard deviation for describing skewed distributions.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Interquartile Range (IQR)** \n",
    "\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Outliers** are defined as:\n",
    "\n",
    "- below Q1 - 1.5 * IQR\n",
    "- above Q3 + 1.5 * IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Let's see how box plots are generated so we can best interpret them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## first, read in the drinks data\n",
    "drink_cols = ['country', 'beer', 'spirit', 'wine', 'liters', 'continent']\n",
    "url = './datasets/drinks.csv'\n",
    "drinks = pd.read_csv(url, header=0, names=drink_cols, na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# print the spirit column (sorted)\n",
    "drinks.spirit.sort_values().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# show \"five-number summary\" for spirit\n",
    "drinks.spirit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# examine with box plot\n",
    "drinks.spirit.plot(kind='box');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# include multiple variables\n",
    "drinks.drop('liters', axis=1).plot(kind='box');\n",
    "\n",
    "# Or just: drinks.drop('liters', axis=1).boxplot();\n",
    "# (This only works on DataFrames, not Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### *Grouped* box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# example 1: box plot of beer servings grouped by continent\n",
    "drinks.boxplot(column='beer', by='continent');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# example 2: box plot of all numeric columns grouped by continent\n",
    "drinks.boxplot(by='continent');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"distance\"></a>\n",
    "### Measuring distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### How do we measure distance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One method is to take the difference between two points:\n",
    "\n",
    "$$X_2 - X_1$$\n",
    "\n",
    "However, this can be inconvenient because of negative numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We often use the following square root trick to deal with negative numbers.\n",
    "\n",
    "$$\\sqrt{(X_2-X_1)^2} = | X_2 - X_1 |$$\n",
    "\n",
    "> - Note this is equivalent to the absolute value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What about distance in multiple dimensions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can turn to the Pythagorean theorem.\n",
    "\n",
    "$$a^2 + b^2 = c^2$$\n",
    "\n",
    "To find the distance along a diagonal, it is sufficient to measure one dimension at a time:\n",
    "\n",
    "$$\\sqrt{a^2 + b^2} = c$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*More generally*, we can write this as the norm (You'll see this in machine learning papers):\n",
    "\n",
    "$$\\|X\\|_2 = \\sqrt{\\sum{x_i^2}} = c$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What if we want to work with points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For points $\\vec{x}: (x_1, x_2)$ and $\\vec{y}: (y_1, y_2)$ we can write:\n",
    "\n",
    "$$\\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2} = c$$\n",
    "$$or$$\n",
    "$$\\sqrt{\\sum{(x_i - y_i)^2}} = c$$\n",
    "$$or$$\n",
    "$$\\| \\vec{x} - \\vec{y} \\| = c$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> You may be more familiar with defining points as $(x, y)$ rather than $(x_1, x_2)$. \n",
    "> - However, in machine learning it is much more convenient to **define each coordinate using the same base letter with a different subscript**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> - This allows us to easily represent a 100-dimensional point, e.g., $(x_1, x_2, ..., x_{100})$. \n",
    "> - If we use the other method, we would soon run out of letters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"dispersion\"></a>\n",
    "### Measures of dispersion: Standard deviation and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Standard deviation** (SD, $\\sigma$ for population standard deviation, or $s$ for sample standard deviation) is a measure that is used to quantify the amount of *variation or dispersion from the mean* of a set of data values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A ***low*** standard deviation means that most of the numbers are close to the average. \n",
    "- A ***high*** standard deviation means that the numbers are spread out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Standard deviation (i.e. $\\sigma$) is the square root of variance:\n",
    "\n",
    "$$variance = \\frac {\\sum{(x_i - \\bar{X})^2}} {n-1}$$\n",
    "\n",
    "$$s = \\sqrt{\\frac {\\sum{(x_i - \\bar{X})^2}} {n-1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> **Standard deviation** is often used because it is *in the same units as the original data!* \n",
    "> - By glancing at the standard deviation, we can immediately estimate how \"typical\" a data point might be by how many standard deviations it is from the mean. \n",
    "> - Furthermore, standard deviation is the only value that makes sense to visually draw alongside the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> **Variance** is often used for efficiency in computations. \n",
    "> - The square root in the SD always increases with the function to which it is applied. \n",
    "> - So, removing it can *simplify* calculations (e.g., taking derivatives), particularly for tasks such as optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"ie3\"></a>\n",
    "#### Independent exercise 3 (~10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# assign the first 5 rows of the beer data from drinks to a variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the mean of the beer data by hand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# calculate variance by hand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# calculate standard deviation by hand\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the mean, variance, and standard deviation using Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"distributions\"></a>\n",
    "## Understanding distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What is an event space?\n",
    "  - A listing of all possible occurrences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What is a probability distribution?\n",
    "  - A function that describes how events occur in an event space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What are general properties of probability distributions?\n",
    "  - All probabilities of an event are between 0 and 1.\n",
    "  - A probability near 1 means that something is almost certain to occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"what\"></a>\n",
    "### What is the Normal Distribution?\n",
    "\n",
    "- A normal distribution is often a *key assumption* to many models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  - In practice, if the normal distribution assumption is not met, it's *not* the end of the world. \n",
    "  - Your model is just less efficient in most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The normal distribution depends on the *mean* and the *standard deviation*.\n",
    "    - The mean determines the center of the distribution. \n",
    "    - The standard deviation determines the height and width of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./assets/normal.png\" style=\"margin: auto; width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Normal distributions are symmetric, bell-shaped curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When the standard deviation is large, the curve is short and wide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When the standard deviation is small, the curve is tall and narrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Why do we care about normal distributions?\n",
    "\n",
    "- They often show up in nature.\n",
    "- Aggregated processes tend to distribute normally, regardless of their underlying distribution — provided that the processes are uncorrelated or weakly correlated (central limit theorem).\n",
    "- They offer effective simplification that makes it easy to make approximations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Plot a histogram of 1,000 samples from a random normal distribution:\n",
    "\n",
    "The `np.random.randn(numsamples)` function will draw from a random normal distribution with a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "- To plot a histogram, pass a NumPy array with 1000 samples as the only parameter to `plt.hist()`.\n",
    "- Change the number of bins using the keyword argument `bins`, e.g. `plt.hist(mydata, bins=50)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of several random normal samples from NumPy\n",
    "plt.hist(np.random.randn(1000), bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"sampling\"></a>\n",
    "## Sampling bias\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"https://imgs.xkcd.com/comics/ayn_random_2x.png\" style=\"margin: auto; width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Sampling bias** occurs when a sample is collected in such a way that some members of the intended population are more or less likely to be included than others.\n",
    "\n",
    "- This can happen when a sample is taken non-randomly — either implicitly or explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When we have non-random sampling that results in sampling bias, it can affect the inferences or results of our analyses. \n",
    "- We must be careful not to attribute our results to the process we observe when they could actually be because of a bias in our sampling.\n",
    "\n",
    "> - ***Basically:*** When we have sampling bias, we aren't measuring what we think we are measuring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Examples of sampling bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Pre-screening:** Purposely restricting the sample to a specific group or region.\n",
    "    - This typically happens when people try to study priority areas to save costs and assume priority areas are the same as random areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Self-selection:** When someone has the ability to non-randomly decide what is included in a sample.\n",
    "    - This typically happens in surveys and polls but can also be an issue with other kinds of reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Survivorship bias:** When we select only surviving subjects in a sample over time.\n",
    "    - This might happen when we only look at existing customers and assume they have the same characteristics as new customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Problems That Arise From Sampling Bias\n",
    "- We could overestimate or underestimate means and sample statistics.\n",
    "- It's possible to have artificial correlation where there should be none."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### A solution: Stratified random sampling\n",
    "\n",
    "We've discussed how it is important to obtain a random sample of our population. \n",
    "- However, sometimes it is more effective to apply some reasoning to our sampling process. \n",
    "- By optimizing how we choose samples, we can possibly create a more accurate model using fewer samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "***Stratified random sampling*** ensures we capture important population characteristics in the random sample. \n",
    "- We effectively break the population into \"strata\" (groups), then randomly sample from each group to obtain our overall sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- *For example*, if we know that the population is half males and half females, we can make sure that our sample is half male and half female.\n",
    "- This method depends on knowing **key population statistics**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"relationships\"></a>\n",
    "## Measuring relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"covariance\"></a>\n",
    "### Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "***Covariance*** is a measure of the *joint variability* between two random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can think of this as a measure of linear association. If you have a variance of Y and a variance of X, the covariance is the amount of variance they share.\n",
    "\n",
    "$$cov(X, Y) = \\frac {\\sum{(x_i - \\bar{X})(y_i - \\bar{Y})}} {n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> We can gain insight into covariance by looking closely at the formula above. First, observe that the formula effectively pairs the first $x$ data point with the first $y$ data point: $(x_1, y_1)$. All computations are done solely on these pairs of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> Second, let's ask ourselves, **when would covariance be positive**? \n",
    "> - From the numerator, covariance would be positive if, for all pairs of data points, $(x_i - \\bar{X})$ and $(y_i - \\bar{Y})$ are:\n",
    ">\n",
    ">     1) *both positive  \n",
    ">     **or**   \n",
    ">     2) both negative*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> This occurs when: \n",
    "> 1. Both data points are greater than their respective means.  \n",
    "> **-or-**\n",
    "> 2. Both data points are less than their respective means.\n",
    ">\n",
    "> So, if the $x$ data points vary from their mean in the same way the $y$ data points vary from their mean, covariance will be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> Third, let's consider: **Might outliers affect covariance?** \n",
    "> - *Yes!* Given the structure of the formula (a sum of terms), a large outlier pair far from the means could strongly pull the covariance in one direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Covariance Expressed Using Matrix Notation**\n",
    "\n",
    "$$cov(\\mathbf{X}, \\mathbf{Y}) = \\mathbb{E}[(\\mathbf{X}-\\mathbb{E}[\\mathbf{X}])(\\mathbf{Y}-\\mathbb{E}[\\mathbf{Y}])]$$\n",
    "\n",
    "**A Useful Special Case (Used Below)**\n",
    "\n",
    "$$cov(X, X) = \\frac {\\sum{(x_i - \\bar{X})^2}} {n} = var(X) = \\sigma_X^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"correlation\"></a>\n",
    "### Correlation\n",
    "\n",
    "While *covariance* is a useful measure, it can be difficult to compare covariances, as they are **not *standardized***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Instead we can use the ***correlation***, which measures the same effect but reports it as a range from -1 to 1. \n",
    "- 1 represents perfect covariance and correlation.\n",
    "- 0 represents no correlation.\n",
    "- -1 represents perfect inverse correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The following visual examples better illustrate how correlation refers to how $X$ and $Y$ change together. Notice that a correlation number by itself is not always indicative of the relationship between the variables — always try to supplement 2-D correlation with a visual!\n",
    "\n",
    "<img src=\"./assets/correlations.png\" style=\"margin: auto; width: 750px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$corr(X,Y) = \\frac {cov(X,Y)} {\\sigma_X\\sigma_Y} = \\frac {\\mathbb{E}[(\\mathbf{X}-\\mathbb{E}[\\mathbf{X}])(\\mathbf{Y}-\\mathbb{E}[\\mathbf{Y}])]} {\\sigma_X\\sigma_Y}$$\n",
    "\n",
    "Note that the variance is always positive, making the denominator positive. \n",
    "- So, the sign of the covariance between $X$ and $Y$ is the same as the sign of their correlation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"matrix\"></a>\n",
    "### The variance-covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For our purposes in modeling and machine learning, the fastest way to get a preview of the underlying relationships in our data is to use the *variance-covariance matrix*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The variance-covariance matrix shows the covariance between every variable in our data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given $n$ features from $X_1$ to $X_n$, the variance-covariance matrix looks like this (recall that $cov(X, X) = var(X)$):\n",
    "\n",
    "$$\\left[ \\begin{array}{c}\n",
    "var(X_1) & cov(X_1,X_2) & ... & cov(X_1,X_n)  \\\\\n",
    "cov(X_2,X_1) & var(X_2) & ... & cov(X_2,X_n)  \\\\\n",
    "... & ... & ... & ... \\\\\n",
    "cov(X_n,X_1) & cov(X_n,X_2) & ... & var(X_n)\n",
    "\\end{array} \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "From a quick glance at this matrix, we can glean insight about which variables might be strongly correlated.\n",
    "> **Note:** Strongly-correlated features may indicate redundant features and/or negatively affect some models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If data are centered around the mean, every column has its mean subtracted from itself. So, the *mean for every column is now 0*. You can then compute the variance-covariance matrix as:\n",
    "\n",
    "$$\\frac {X^TX} {n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "> Those of you who have been exposed to linear regression may recognize this term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"ie4\"></a>\n",
    "#### Independent exercise 4\n",
    "- Continue using advertising data (i.e. `data`) for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. calculate the variance-covariance matrix (make sure to de-mean the data, first!)\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or using built-in method in Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. calculate the correlation matrix using the DataFrame's built-in `.corr()` method\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When we have a large amount of data, the correlation matrix may be too difficult to read. Let's *make a plot*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# 3. use Seaborn's `.heatmap()` function to make a plot of the correlation matrix\n",
    "# - remember that we imported Seaborn as `sns`\n",
    "# - to make a correlation matrix from a DataFrame, try `my_df.corr()`\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Of course, looking at linear association doesn't show us the whole picture. We can get a more detailed look with a *scatterplot matrix*.\n",
    "- see if you can guess or [figure out](http://seaborn.pydata.org/generated/seaborn.pairplot.html) how `pairplot()` might work.\n",
    "- `pairplot()` plots each column against each column of a DataFrame. So, at the minimum you must have to pass in the DataFrame you want to analyze, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. use Seaborn's `.pairplot()` function to make joint scatterplots of the data\n",
    "\n",
    "# Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"optional\"></a>\n",
    "# Optional\n",
    "> Proceed with caution... *(if you dare!!!)*\n",
    "\n",
    "<img src=\"https://r.hswstatic.com/w_907/gif/92d82dd6dbe8bee36364cd064aa20b3a-raiders-lost-ark.jpg\" style=\"margin: auto; width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"missing\"></a>\n",
    "## Missing data\n",
    "---\n",
    "\n",
    "Sometimes we are unable to collect every attribute for a particular observation.\n",
    "\n",
    "Unfortunately, this makes the observation unusable until we decide how to deal with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**We have to decide whether to:**\n",
    "- Drop the observation.\n",
    "- Drop the attribute.\n",
    "- Impute a value for that specific attribute and observation.\n",
    "\n",
    "**So,** how do we decide?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"types\"></a>\n",
    "### Types of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **Missing completely at random (MCAR)**\n",
    "    - The reason that the data are missing is completely random and introduces no sampling bias.\n",
    "    - In this case, it's safe to drop or impute.\n",
    "    - We can test for this by looking at other attributes for missing and non-missing groups to see if they match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **Missing at random (MAR)**\n",
    "    - The data are missing in a way that is related to another factor.\n",
    "    - This is a form of sampling bias.\n",
    "    - Like other instances of sampling bias, we can fix this by modeling the selection process.\n",
    "        - This is done by building a model to impute the missing value based on other variables.\n",
    "> *For example,* if a sensor tends to fail at certain times, it will bias the values it indicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **Missing not at random (MNAR)**\n",
    "    - The response is missing in a way that relates to its own value.\n",
    "    - We can't test for this.\n",
    "    - We also can't fix this in a reasonable way.\n",
    "> *For example,* if a sensor tends to fail at high loads, it will be biased towards reporting low load values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### De minimis\n",
    "- If few enough observations are missing, it's not likely to change our results to a meaningful degree.\n",
    "- In these cases, we don't have to bother with trivialities and simply pick a method that works well enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"class\"></a>\n",
    "### Class imbalance\n",
    "\n",
    "Sometimes (i.e. *most* of the time) our sample may include an over-representation of one type of class. \n",
    "- For example, airport security may have 990 X-ray scans showing the absence of a weapon. Due to natural scarcity, it may only provide 10 scans showing a weapon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- If our goal is to create a model that indicates whether or not a weapon is present, then we are at a disadvantage. **Ignoring the class imbalance** would lead to a model that _always guesses that a weapon is not present!_\n",
    "    - Note that most optimization procedures optimize for training data accuracy. Always guessing that a weapon is absent leads to 990/1000 correct results; an accuracy of 99 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- A simple way to get around this is to **undersample** the majority class, deliberately leaving us with a balanced data set of 10 each. However, this is less than ideal, as it effectively ignores much of the available data.\n",
    "\n",
    "- Alternatively, we could **oversample** the minority class by duplicating examples. Again, this is not ideal. Because we have very little data, this will magnify small differences that may just be errors, leading to a model that overfits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> Later in the course, we will look at additional methods for training models to work around class imbalance. \n",
    ">\n",
    "> - For example, we may use an optimization algorithm that cares less about accuracy and more about minimizing particular **error types**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"error\"></a>\n",
    "### Error types\n",
    "\n",
    "Statisticians often classify errors not just as errors but as one of two specific types of errors — type I and type II."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ **Type I errors** are false positives.\n",
    "    - Machine learning: Our model falsely predicts \"positive.\" (The prediction is incorrect.)\n",
    "    - Statistics: Incorrect rejection of a true null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ **Type II errors** are false negatives.\n",
    "    - Machine learning: Our model falsely predicts \"negative.\" (The prediction is incorrect.)\n",
    "    - Statistics: Incorrectly retaining a false null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Understanding these errors can be especially beneficial when designing models. For example, we might decide that type I errors are OK but type II errors are not. We can then optimize our model appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> **Example 1:** Suppose we make a model for airline security in which we predict whether or not a weapon is present (\"positive\"). In this case, we would much rather have type I errors (falsely predict a weapon) than type II errors (falsely predict no weapon)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> **Example 2:** Suppose we make a model for the criminal justice system in which we whether or not a defendant is guilty (\"positive\"). In this case, we would much rather have type II errors (falsely predict innocent) than type I errors (falsely predict guilty)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"hypothesis\"></a>\n",
    "## Introduction to hypothesis testing\n",
    "---\n",
    "\n",
    "**Objective**: Test a hypothesis within a sample case study.\n",
    "\n",
    "You'll remember that we've worked previously on descriptive statistics such as mean and variance. \n",
    "- How would we tell if there is a difference between our groups? \n",
    "- How would we know if this difference was real or if our finding is simply the result of chance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For *example*, if we are working on sales data, how would we know if there was a difference between the buying patterns of men and women at Acme, Inc.? **Hypothesis testing!**\n",
    "\n",
    "> **Note:** In this course, hypothesis testing is primarily used to assess foundational models such as linear and logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Hypothesis testing steps\n",
    "\n",
    "Generally speaking, we start with a **null hypothesis** and an **alternative hypothesis**, which is the opposite of the null. Then, you check whether the data support rejecting your null hypothesis or fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example:\n",
    "\n",
    "- Null hypothesis: There is no relationship between gender and sales.\n",
    "- Alternative hypothesis: There is a relationship between gender and sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that \"failing to reject\" the null hypothesis is *not* the same as \"accepting\" it. \n",
    "- Your alternative hypothesis may indeed be true, but you don't necessarily have enough data to show that yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> This distinction is *crucial* for helping you avoid overstating your findings. \n",
    ">\n",
    "> - **You should only state what your data and analysis can truly represent!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"validate\"></a>\n",
    "### Validate your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### How Do We Tell if the Association We Observed is Statistically Significant?\n",
    "\n",
    "Statistical significance is the likelihood that a result or relationship is caused by something other than mere random chance. \n",
    "- Statistical hypothesis testing is traditionally employed to determine whether or not a result is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We might ask: **How likely is the effect observed to be true, assuming the null hypothesis is true?** \n",
    "- If the probability of our observation occurring by chance is **less than 5 percent** (supposing the null hypothesis), then we reject the null hypothesis. \n",
    "> Note that the 5 percent value is in many ways arbitrary — many statisticians require even higher confidence levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The probability of our observations occurring by chance, given the null hypothesis, is the **p-value** ($p$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> **Example:** Suppose you flip a coin three times and get three heads in a row. These three flips are our observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> + We want to know whether or not the coin is fair. So, we select the **null hypothesis: The coin is fair.**\n",
    "> + Now, let's suppose the null hypothesis is true. Three heads in a row occurs with a chance of $1/2^3 \\approx 12.5\\%$.\n",
    "> + Because there is a reasonable ($> 5\\%$) chance of three heads occuring naturally, we do not reject the null hypothesis.\n",
    "> + So, **we conclude** that we do not have enough data to tell whether or not the coin is fair ($p = 0.125$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In other words, we say that something is NOT statistically significant if there is a less than 5 percent chance that our finding was caused by chance alone (assuming the null hypothesis is true)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"confidence\"></a>\n",
    "### Confidence intervals\n",
    "\n",
    "A closely related concept is **confidence intervals**. \n",
    "- A 95 percent confidence interval can be interpreted like so: \n",
    "\n",
    "    ***Under infinite sampling of the population, we would expect that the true value of the parameter we are estimating to fall within that range 95% of the time.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Keep in mind that we only have a **single sample of data** and not the **entire population of the data**. \n",
    "- The \"true\" effect/difference is either within this interval or it is not. \n",
    "- We have no firm knowledge, however, that our single estimate of the \"true\" effect/difference is close or not to the \"truth\". \n",
    "- The confidence interval around our estimate tells us, with a given sample size and level of confidence, the range in which future estimates are likely to fall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> **Note** that using 95 percent confidence intervals is just a convention. \n",
    "> - You can create 90 percent confidence intervals (which will be more liberal), 99 percent confidence intervals (which will be more conservative), or whatever intervals you prefer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"relation\"></a>\n",
    "### Relation to machine learning\n",
    "\n",
    "Many of the topics discussed in this lesson are used in both statistics and machine learning. However, some of the terminology differs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Throughout this lesson, we have discussed **variables** (typically **independent variables** and **dependent variables**). \n",
    "- For *example*, we might be given the **linear estimator** $Y = mX + b$. \n",
    "- We could say that this contains two variables ($X$ - independent and $Y$ - dependent (i.e., the prediction, as it depends on $X$)), a coefficient of $m$, and the constant of $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In machine learning, we typically rewrite this as a function — $\\hat{y}(x) = mx + b$ — and call it a **linear model**. \n",
    "- The predicted value is $\\hat{y}(x)$ (\"prediction\" is denoted by the carat), which is dependent on $x$. \n",
    "- We might call $x$ a **feature** rather than a variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> **Example:** Suppose a house price $P$ is linearly dependent on its square footage $S$. \n",
    "- So, we might predict $P = cS + b$, where $c$ and $b$ are constants. \n",
    "- Alternatively, we could write $\\hat{p}(s) = cs + b$. \n",
    "- Here, we took a complicated house and modeled it using a single feature — its square footage. \n",
    "- Of course, we are likely missing many confounding variables/features that also affect the price! \n",
    "- So, our model likely contains a lot of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"practice\"></a>\n",
    "**Additional practice materials** within `./practice/`:\n",
    "- [A/B testing](./practice/AB-testing.ipynb)\n",
    "- [EDA w/ music data](./practice/eda-with-billboard-data-lab.ipynb)\n",
    "- [EDA w/ telecomm data](./practice/telecomm-eda-group-lab.ipynb)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
