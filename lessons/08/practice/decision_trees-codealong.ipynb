{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "#  Decision Trees & Random Forests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install Pydot: `$ conda install pydot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step One: Load in the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/titanic.csv', 'r') as csvfile:\n",
    "    titanic_reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    \n",
    "    # header contains feature names\n",
    "    row = next(titanic_reader)\n",
    "    feature_names = np.array(row)\n",
    "    \n",
    "    # load dataset, and target classes\n",
    "    titanic_X, titanic_y = [], []\n",
    "    for row in titanic_reader:  \n",
    "        titanic_X.append(row)\n",
    "        titanic_y.append(row[0]) # The target value is \"survived\"\n",
    "    \n",
    "    # changing to arrays\n",
    "    titanic_X = np.array(titanic_X)\n",
    "    titanic_y = np.array(titanic_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect last row, header, features and target\n",
    "print(f'Last Row: {row}')\n",
    "print(f'Header: {feature_names}')\n",
    "print(f'First Row: {titanic_X[0]}')\n",
    "print(f'Target: {titanic_y[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the 'class', 'age' and 'sex' variables (2nd, 5th, and 4th features)\n",
    "titanic_X = titanic_X[:, [1, 4, 3]]\n",
    "feature_names = feature_names[[1, 4, 3]]\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Two: Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = titanic_X[:, 1]\n",
    "titanic_X[ages != '', 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'age' contains missing values, so we're going to assign the mean value \n",
    "#   (for all of the elements in 'age')\n",
    "ages = titanic_X[:, 1]\n",
    "# convert strings to floats then average\n",
    "mean_age = np.mean(titanic_X[ages != '', 1].astype(np.float))\n",
    "\n",
    "# update 'age' column\n",
    "titanic_X[titanic_X[:, 1] == '', 1] = mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encode 'sex' as a categorical variable\n",
    "# normalize our class variables by giving them easily interpreted labels\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "enc = LabelEncoder()\n",
    "\n",
    "# create categorical classes for 'sex' (the 3rd variable)\n",
    "label_encoder = enc.fit(titanic_X[:, 2])\n",
    "\n",
    "print(\"Categorical classes:\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create numerical classes for 'sex'\n",
    "integer_classes = label_encoder.transform(label_encoder.classes_)\n",
    "print(\"Integer classes:\", integer_classes)\n",
    "\n",
    "# update 'sex' column\n",
    "titanic_X[:, 2] = label_encoder.transform(titanic_X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect one row of X and y\n",
    "print(feature_names, 'target')\n",
    "print(titanic_X[5], titanic_y[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now encode 'class', which has more than 2 possible values\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# create categorical classes for 'class' (the 1st variable)\n",
    "enc = LabelEncoder()\n",
    "label_encoder = enc.fit(titanic_X[:, 0])\n",
    "\n",
    "print(\"Categorical classes:\", label_encoder.classes_)\n",
    "\n",
    "# create numerical classes for 'class'\n",
    "integer_classes = label_encoder.transform(label_encoder.classes_)\n",
    "print(\"Integer classes:\", integer_classes)\n",
    "\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "one_hot_encoder = enc.fit(integer_classes.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, convert classes to integers using label_encoder\n",
    "t = label_encoder.transform(titanic_X[:, 0])\n",
    "t[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second, create a sparse matrix with three columns, \n",
    "#   each one indicating if the instance belongs to the class\n",
    "new_features = one_hot_encoder.transform(t.reshape(-1, 1))\n",
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the new features to titanic_X\n",
    "titanic_X = np.concatenate([titanic_X, new_features.toarray()], axis = 1)\n",
    "\n",
    "# delete converted column (now redundant)\n",
    "titanic_X = np.delete(titanic_X, [0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update feature names\n",
    "feature_names = ['age', 'sex', 'first_class', 'second_class', 'third_class']\n",
    "\n",
    "# convert to numerical values\n",
    "titanic_X = titanic_X.astype(float)\n",
    "titanic_y = titanic_y.astype(float)\n",
    "\n",
    "# inspect\n",
    "print(feature_names)\n",
    "print(titanic_X[0], titanic_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Three: Create Split!\n",
    "<img src='https://media.giphy.com/media/LWQVG2QJwUgla/giphy.gif' style=\"float: center; height: 150px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic_X, titanic_y, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Four: Decision Trees!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# instantiate tree using entropy to measure information gain\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_leaf=5)\n",
    "# fit the decision tree with the data\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize our trained tree, using pydot\n",
    "import pydot\n",
    "import os\n",
    "from io import StringIO\n",
    "dot_data = StringIO() \n",
    "\n",
    "# export to file via graphviz\n",
    "tree.export_graphviz(clf, out_file=dot_data, feature_names=['age','sex','1st_class','2nd_class','3rd_class']) \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "# write to pdf\n",
    "graph[0].write_pdf('titanic.pdf')\n",
    "\n",
    "print('Image created!')\n",
    "print('Check it out here:', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we just **created a pdf** in our working directory.\n",
    "- Navigate to it through the Finder window and *check it out*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Five: Measure Performance\n",
    "\n",
    "> **_Recall_**,\n",
    "> - **Precision** = true positives/(true positives + false positives)  \n",
    "> i.e. The ability of the classifier to not label a negative sample as positive\n",
    "> - **Recall** = true positives/(true positives + false negatives)  \n",
    "> i.e. The ability of the classifier to find all positive samples\n",
    "> - **f1**  = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to measure model performance\n",
    "from sklearn import metrics\n",
    "\n",
    "def measure_performance(X, y, clf, show_accuracy=True, show_classification_report=True, \n",
    "                        show_confusion_matrix=True):\n",
    "    y_pred=clf.predict(X)   \n",
    "    if show_accuracy:\n",
    "        print(\"Accuracy: {0:.3f}\".format(metrics.accuracy_score(y, y_pred)), \"\\n\")\n",
    "    if show_classification_report:\n",
    "        print(\"Classification report:\")\n",
    "        print(metrics.classification_report(y, y_pred), \"\\n\")\n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y, y_pred), \"\\n\")\n",
    "\n",
    "# measure accuracy, precision, recall, f1 in the training set\n",
    "measure_performance(X_train, y_train, clf, show_classification_report=True, \n",
    "                    show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform leave-one-out cross validation to better measure performance, reducing variance\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from scipy.stats import sem\n",
    "\n",
    "# inspect documentation for LeaveOneOut\n",
    "# help(LeaveOneOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to perform Leave-One-Out cross validation\n",
    "def loo_cv(X_train, y_train, clf):\n",
    "    loo = LeaveOneOut()\n",
    "    scores = np.zeros(X_train[:].shape[0])\n",
    "    \n",
    "    for train_index,test_index in loo.split(X_train):\n",
    "        X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]\n",
    "        y_train_cv, y_test_cv = y_train[train_index], y_train[test_index]\n",
    "        clf = clf.fit(X_train_cv, y_train_cv)\n",
    "        y_pred = clf.predict(X_test_cv)\n",
    "        scores[test_index] = metrics.accuracy_score(y_test_cv.astype(int), \n",
    "                                                    y_pred.astype(int))\n",
    "    \n",
    "    print(\"Mean score: {0:.3f} (+/-{1:.3f})\".format(np.mean(scores), sem(scores)))\n",
    "\n",
    "loo_cv(X_train, y_train, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Six: Improve the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, try for better results using Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=33)\n",
    "loo_cv(X_train, y_train, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now, go back to the decision tree model and try tuning hyperparameters\n",
    "# attempt 1\n",
    "clf_dt = tree.DecisionTreeClassifier(criterion='entropy', \n",
    "                                     max_depth=3,\n",
    "                                     min_samples_leaf=5)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "\n",
    "measure_performance(X_test, y_test, clf_dt)\n",
    "\n",
    "# Inspect documentation for DecisionTreeClassifier\n",
    "# help(tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt 2\n",
    "clf_dt = tree.DecisionTreeClassifier(criterion='gini', \n",
    "                                     max_depth=3,\n",
    "                                     min_samples_leaf=10)\n",
    "clf_dt.fit(X_train,y_train)\n",
    "measure_performance(X_test,y_test,clf_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A New Measure: the ROC and Area Under a Curve (AUC)\n",
    "\n",
    "One way we can score a binary classification is by plotting the *reciever operating characteristic (ROC)* and determining the value of the *area under curve (AUC)*. \n",
    "- Like above, our goal is to see an _**AUC** as close to 1 as possible_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we use metrics to measure roc curve\n",
    "# syntax: roc_curve(actual, prediction, [pos_label if it's not 1])\n",
    "predictions = [p[1] for p in clf_dt.predict_proba(X_train)]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, predictions)\n",
    "\n",
    "# next, measure the auc\n",
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"False-positive rate:\", fpr)\n",
    "print(\"True-positive rate: \", tpr)\n",
    "print(\"Thresholds:         \", thresholds)\n",
    "\n",
    "metrics.roc_auc_score(y_train, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Change some of the assumptions we've made throughout the lab to see how that changes the accuracy; Imputation, tree depth, samples, etc.\n",
    "\n",
    "+ Try to find the most accurate model you can; talk about what you did, address the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
